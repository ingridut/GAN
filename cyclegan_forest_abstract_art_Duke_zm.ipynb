{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN Abstract Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code corresponding to my Duke AI for Art Competition submission. This notebook was ran on a 15\" Windows Surface Book 2 with a NVIDIA GeForce GTX 1060 GPU.<br>\n",
    "\n",
    "Here, I used a CycleGAN to generate abstract pictures of forests. For the CycleGAN, I used the PyTorch implementation from the creators of the CycleGAN. Their library can be found [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"C:\\\\Users\\\\adminUser\\\\Documents\\\\VEGAN\\\\fastai-master\\\\old\")\n",
    "sys.path.append(\"C:\\\\Users\\\\adminUser\\\\Documents\\\\VEGAN\\\\cgan\")\n",
    "sys.path.append(\"C:\\\\Users\\\\adminUser\\\\Documents\\\\VEGAN\\\\cgan\\\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adminUser\\Anaconda3\\envs\\fastai\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "from cgan.options.train_options import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cgan.options.train_options import TrainOptions\n",
    "from cgan.data.data_loader import CreateDataLoader\n",
    "from cgan.models.models import create_model\n",
    "from cgan.util.visualizer import Visualizer\n",
    "from google_images_download import google_images_download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting images for training\n",
    "\n",
    "For training, I used images of \"famous abstract paintings\" and \"forests\" These images were scraped from Google Images. After scraping 400 images, I went through and chose 216 images from each category. These were the images included in training.<br>\n",
    "\n",
    "First downloading \"famous abstract art pictures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #class instantiation\n",
    "# response = google_images_download.googleimagesdownload()   \n",
    "\n",
    "# #creating list of arguments\n",
    "# arguments = {\"keywords\":\"portraits\",\n",
    "#              \"limit\":400,\n",
    "#              \"output_directory\":\"C:\\\\Users\\\\adminUser\\\\Documents\\\\VEGAN\\\\input_data\",\n",
    "#              \"chromedriver\":\"C:\\\\Users\\\\adminUser\\\\Documents\\\\VEGAN\\\\chromedriver.exe\"}   \n",
    "\n",
    "# #passing the arguments to the function\n",
    "# paths = response.download(arguments)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing a couple example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_PATH = Path('input_data/trainA/')\n",
    "painting_PATH = Path('input_data/trainB/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now constructing the CycleGAN Model. Specifying options. If you go to the CycleGAN library linked above, you can see what each of the specifications mean and other options. <br>\n",
    "\n",
    "Just to note, when I first ran this model, it crashed after 180 epochs (I had my laptop closed for a little while), so I had restart the kernel and start training again at 180 epochs. So if you want to run the model from the beginning, please remove the options ***--continue_train*** and ***--epoch_count, 180***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "batchSize: 1\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ./checkpoints\n",
      "continue_train: False\n",
      "dataroot: input_data/\n",
      "dataset_mode: unaligned\n",
      "display_freq: 1\n",
      "display_id: 1\n",
      "display_port: 8888\n",
      "display_single_pane_ncols: 0\n",
      "display_winsize: 300\n",
      "epoch_count: 1\n",
      "fineSize: 300\n",
      "gpu_ids: [0]\n",
      "init_type: normal\n",
      "input_nc: 3\n",
      "isTrain: True\n",
      "lambda_A: 10.0\n",
      "lambda_B: 10.0\n",
      "lambda_identity: 0.5\n",
      "loadSize: 330\n",
      "lr: 0.0002\n",
      "lr_decay_iters: 50\n",
      "lr_policy: lambda\n",
      "max_dataset_size: inf\n",
      "model: cycle_gan\n",
      "nThreads: 8\n",
      "n_layers_D: 3\n",
      "name: nodrop\n",
      "ndf: 64\n",
      "ngf: 64\n",
      "niter: 100\n",
      "niter_decay: 100\n",
      "no_dropout: False\n",
      "no_flip: False\n",
      "no_html: False\n",
      "no_lsgan: False\n",
      "norm: instance\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 50\n",
      "print_freq: 100\n",
      "resize_or_crop: resize_and_crop\n",
      "save_epoch_freq: 5\n",
      "save_latest_freq: 5000\n",
      "serial_batches: False\n",
      "update_html_freq: 1\n",
      "which_direction: AtoB\n",
      "which_epoch: latest\n",
      "which_model_netD: basic\n",
      "which_model_netG: resnet_9blocks\n",
      "-------------- End ----------------\n"
     ]
    }
   ],
   "source": [
    "opt = TrainOptions().parse(['--dataroot', 'input_data/', \n",
    "                            '--nThreads', '8', \n",
    "                            '--name', 'vintage_portrait'\n",
    "                            '--no_dropout','--niter', '100', \n",
    "                            '--loadSize', '330',\n",
    "                            '--fineSize', '300',\n",
    "                            '--display_winsize', '300',\n",
    "                            '--niter_decay', '100',\n",
    "                            '--display_port', '8888',\n",
    "                            '--name', 'nodrop', '--gpu_ids', '0',\n",
    "                            '--update_html_freq', '1',\n",
    "                            '--display_freq','1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now creating the dataset. Just to note it automatically is looking for directories *trainA* and *trainB*. These directories should contain your images. You also have the option of including test images, which should be in directories *testA* and *testB*. Note, I do not have any images here in the test set, since the goal is to create art and not necessarily a model that generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomDatasetDataLoader\n",
      "dataset [UnalignedDataset] was created\n",
      "Size of dataset: 294\n"
     ]
    }
   ],
   "source": [
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "dataset_size = len(data_loader)\n",
    "print ('Size of dataset:', dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below creating the model and also the visualizer, which allows you to visualize the images during training in visdom. It is allows you to save the example training images in a html page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycle_gan\n",
      "initialization method [normal]\n",
      "initialization method [normal]\n",
      "initialization method [normal]\n",
      "initialization method [normal]\n",
      "---------- Networks initialized -------------\n",
      "ResnetGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (11): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (12): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (14): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (15): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (16): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (17): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (18): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (21): ReLU(inplace)\n",
      "    (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (24): ReLU(inplace)\n",
      "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (27): Tanh()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 11378179\n",
      "ResnetGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (11): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (12): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (14): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (15): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (16): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (17): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (18): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): Dropout(p=0.5)\n",
      "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "      )\n",
      "    )\n",
      "    (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (21): ReLU(inplace)\n",
      "    (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (24): ReLU(inplace)\n",
      "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (27): Tanh()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 11378179\n",
      "NLayerDiscriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (4): LeakyReLU(0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (7): LeakyReLU(0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (10): LeakyReLU(0.2, inplace)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 2764737\n",
      "NLayerDiscriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (4): LeakyReLU(0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (7): LeakyReLU(0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (10): LeakyReLU(0.2, inplace)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 2764737\n",
      "-----------------------------------------------\n",
      "model [CycleGANModel] was created\n"
     ]
    }
   ],
   "source": [
    "model = create_model(opt)\n",
    "\n",
    "# visualizer = Visualizer(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training  the model\n",
    "\n",
    "Finally ready to train the model. The code below is pretty much taken from the CycleGAN library, so nothing special there. Just run the cell below and training will start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198it [02:44,  1.23it/s]"
     ]
    }
   ],
   "source": [
    "name = opt.name\n",
    "total_steps = 0\n",
    "\n",
    "for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    iter_data_time = time.time()\n",
    "    epoch_iter = 0\n",
    "\n",
    "    for i, data in tqdm(enumerate(dataset)):\n",
    "        iter_start_time = time.time()\n",
    "        if total_steps % opt.print_freq == 0: t_data = iter_start_time - iter_data_time\n",
    "        #visualizer.reset()\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "        model.set_input(data)\n",
    "        model.optimize_parameters()\n",
    "\n",
    "        if total_steps % opt.display_freq == 0:\n",
    "            save_result = total_steps % opt.update_html_freq == 0\n",
    "            #visualizer.display_current_results(model.get_current_visuals(), epoch, save_result)\n",
    "\n",
    "        if total_steps % opt.print_freq == 0:\n",
    "            errors = model.get_current_errors()\n",
    "            t = (time.time() - iter_start_time) / opt.batchSize\n",
    "\n",
    "        if total_steps % opt.save_latest_freq == 0:\n",
    "            print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "            model.save(name + '_latest')\n",
    "\n",
    "        iter_data_time = time.time()\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))\n",
    "        model.save(str(epoch)+'_'+name)\n",
    "\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "    model.update_learning_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualzing the results\n",
    "\n",
    "Now finially ready to visualize the results. Below I just show the generated forests pictures because they are of interest. Note, below I did not visualize them all because it made the notebook too large, but all of the images are available in the Github repository.<br>\n",
    "\n",
    "I am loading the pretrained model so I just set *--epoch_count* to *201*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = TrainOptions().parse(['--dataroot', 'data/input_data/', \n",
    "                            '--nThreads', '8', \n",
    "                            '--no_dropout',\n",
    "                            '--niter', '100', \n",
    "                            '--niter_decay', '100', \n",
    "                            '--name', 'nodrop', \n",
    "                            '--gpu_ids', '0',\n",
    "                            '--update_html_freq', '1',\n",
    "                            '--display_freq','1',\n",
    "                            '--continue_train',\n",
    "                            '--epoch_count', '5', \n",
    "                            '--which_epoch', 'abstract_coral_but_largerlatest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(opt)\n",
    "model.opt.isTrain=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show images\n",
    "def show_img(im, ax=None, figsize=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    return ax\n",
    "\n",
    "# Function to generate one image. Funciton called two cells below\n",
    "def get_one(data):\n",
    "    model.set_input(data)\n",
    "    model.test()\n",
    "    return list(model.get_current_visuals().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of generated forest images\n",
    "generated_forest_ims = []\n",
    "for i,o in enumerate(dataset):\n",
    "    try:\n",
    "        vis = get_one(o)\n",
    "        generated_forest_ims.append(vis)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of where to save images\n",
    "OUT_PATH = Path('C:\\\\Users\\\\adminUser\\\\Documents\\\\VEGAN\\\\generated_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing and saving generated forest images. Here are only 10 beacuse printing more made the notebook too lagre.\n",
    "fig,axes = plt.subplots(2,5,figsize=(15,10))\n",
    "for i, ax in enumerate(axes.flat): \n",
    "    # Uncomment the line below if you would like to visualize all of the images\n",
    "    #if i == 10: break\n",
    "    show_img(generated_forest_ims[i][1],ax)\n",
    "    ax.set_title(i,fontsize=20)\n",
    "    # Uncomment line below if you would like to save the images\n",
    "    #plt.imsave((OUT_PATH/f'{i}.png'),generated_forest_ims[i][5])\n",
    "    \n",
    "for i in range(len(generated_forest_ims)):\n",
    "    plt.imsave((OUT_PATH/f'{i}.png'),generated_forest_ims[i][1])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,3,figsize=(15,10))\n",
    "for i, ax in enumerate(axes.flat): \n",
    "    # Uncomment the line below if you would like to visualize all of the images\n",
    "    #if i == 10: break\n",
    "    show_img(generated_forest_ims[23][i],ax)\n",
    "    ax.set_title(i,fontsize=20)\n",
    "    \n",
    "    # Uncomment line below if you would like to save the images\n",
    "    #plt.imsave((OUT_PATH/f'{i}.png'),generated_forest_ims[i][5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
